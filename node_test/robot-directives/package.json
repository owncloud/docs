{
  "name": "robot-directives",
  "description": "Parse robot directives within HTML meta and/or HTTP headers.",
  "version": "0.3.0",
  "license": "MIT",
  "homepage": "https://github.com/stevenvachon/robot-directives",
  "author": {
    "name": "Steven Vachon",
    "email": "contact@svachon.com",
    "url": "http://www.svachon.com/"
  },
  "main": "lib",
  "repository": {
    "type": "git",
    "url": "git://github.com/stevenvachon/robot-directives.git"
  },
  "bugs": {
    "url": "https://github.com/stevenvachon/robot-directives/issues"
  },
  "dependencies": {
    "isbot": "^2.0.0",
    "useragent": "^2.1.8"
  },
  "devDependencies": {
    "chai": "^3.5.0",
    "mocha": "^2.4.5",
    "object.assign": "^4.0.3"
  },
  "engines": {
    "node": ">= 0.10"
  },
  "scripts": {
    "test": "mocha test.js --reporter spec --check-leaks --bail"
  },
  "files": [
    "lib",
    "license"
  ],
  "keywords": [
    "crawlers",
    "header",
    "html",
    "http",
    "meta",
    "metadata",
    "nofollow",
    "noindex",
    "robots",
    "robots.txt",
    "seo",
    "spiders"
  ]
}
